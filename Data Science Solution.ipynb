{
 "metadata": {
  "name": "",
  "signature": "sha256:e20f8dd99c723db7f6fba21485df66e10a763f73cfd7e471138efb25b3d57bd4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1) Give us your suggestions on how we could make our data set better / more useful."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "  1. Data set can be enhanced by including more transaction data for each product such as number of customers, purchase time, payment method, returned customers, georaphical region, promotion, and so on. These information can further benefit our model for brands ranking and products relationship based on our user profile, and popularity of products based on transaction history. Furthermore, a recommender system could be implemented based on our ranking model to recommend related products with high ranking to customers who clicked on certain products. \n",
      "  \n",
      "  \n",
      "  2. Tidying up the data set. For the last 15 columns, we might consider splitting them into individual groups without overlapping. For example, instead of net_sale_count_last_30days, and net_sale_count_last_7days, we could have net_sale_count_last_7days, and net_sale_count_first_23days_of_last_month, and also further substract net_sale_count_last_30days from net_sale_count to get net_sale_before_last_month. Also, there are some brand names spelled wrongly as datetime formats. \n",
      "  \n",
      "  \n",
      "  3. Certain column and its datatype can be explained more clearly, like 'activated_at'. For entries with missing special_price values, do we understand as same with original_price? "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2) With the given dataset, can you come up with a scientific approach and model for our ranking?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "A predictive model (randome forest) predicting top sellers for the coming week "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This model is used to predict top sellers for the coming week, based on past three weeks' transaction data (we will train the model by using transaction data of last_30days substract with data of last_7days in order to predict top sellers for last_7days) \n",
      "\n",
      "The evaluation metrics for top sellers can be considered as the follows (predicted values): \n",
      "\n",
      "\n",
      "   1) Net sale \n",
      "   \n",
      "   \n",
      "   2) Views/impressions rate\n",
      "   \n",
      "   \n",
      "   3) Least returned/rejected rate\n",
      "   \n",
      "   \n",
      "   4) Views-to-sales converted rate\n",
      "   \n",
      "   \n",
      "   5) Other metrics\n",
      "   \n",
      "\n",
      "The model will be able to predict weekly and the predicted top sellers can be used for promotion purposes in the coming week. \n",
      "\n",
      "However for demonstration purpose, the evaluation metrics used here is the predicted net sale for the last week. (i.e. the column:  net_sale_count_last_7days)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3) How would you test, train, and evaluate your model?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The process to test, train and evaluate my model can be summarized as "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "1. Data cleaning / feature engineering"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "2. Model training"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "3. Testing/validation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1. Data cleaning / feature engineering"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "df = pd.read_csv('products.csv')\n",
      "df.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>product_id</th>\n",
        "      <th>colors</th>\n",
        "      <th>gender</th>\n",
        "      <th>activated_at</th>\n",
        "      <th>season_group</th>\n",
        "      <th>brand</th>\n",
        "      <th>original_price</th>\n",
        "      <th>special_price</th>\n",
        "      <th>sub_cat_type</th>\n",
        "      <th>cat_type</th>\n",
        "      <th>...</th>\n",
        "      <th>impressions_count_last_30days</th>\n",
        "      <th>net_sale_count</th>\n",
        "      <th>net_sale_count_last_7days</th>\n",
        "      <th>net_sale_count_last_30days</th>\n",
        "      <th>rejected_returned_sale_count</th>\n",
        "      <th>rejected_returned_sale_count_last_7days</th>\n",
        "      <th>rejected_returned_sale_count_last_30days</th>\n",
        "      <th>canceled_sale_count</th>\n",
        "      <th>canceled_sale_count_last_7days</th>\n",
        "      <th>canceled_sale_count_last_30days</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 254010</td>\n",
        "      <td>  green</td>\n",
        "      <td> Female</td>\n",
        "      <td> 2014-04-11 17:44:47</td>\n",
        "      <td> Autumn / Winter</td>\n",
        "      <td>         Wardah</td>\n",
        "      <td>  22112</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>   Cleansers &amp; Toners</td>\n",
        "      <td>                  Beauty</td>\n",
        "      <td>...</td>\n",
        "      <td>  6810</td>\n",
        "      <td> 196</td>\n",
        "      <td> 5</td>\n",
        "      <td> 42</td>\n",
        "      <td> 133</td>\n",
        "      <td> 1</td>\n",
        "      <td> 24</td>\n",
        "      <td>  85</td>\n",
        "      <td> 2</td>\n",
        "      <td> 27</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 257247</td>\n",
        "      <td>  brown</td>\n",
        "      <td> Female</td>\n",
        "      <td> 2014-01-17 12:59:56</td>\n",
        "      <td> Autumn / Winter</td>\n",
        "      <td>       Sidewalk</td>\n",
        "      <td> 308449</td>\n",
        "      <td> 119607</td>\n",
        "      <td>    Ballerina &amp; Flats</td>\n",
        "      <td>                   Shoes</td>\n",
        "      <td>...</td>\n",
        "      <td> 17780</td>\n",
        "      <td> 315</td>\n",
        "      <td> 1</td>\n",
        "      <td>  8</td>\n",
        "      <td> 172</td>\n",
        "      <td> 4</td>\n",
        "      <td> 18</td>\n",
        "      <td>  69</td>\n",
        "      <td> 3</td>\n",
        "      <td> 19</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 259356</td>\n",
        "      <td>  beige</td>\n",
        "      <td>   Male</td>\n",
        "      <td> 2014-01-21 16:34:25</td>\n",
        "      <td> Autumn / Winter</td>\n",
        "      <td> Noir Sur Blanc</td>\n",
        "      <td> 350911</td>\n",
        "      <td> 279273</td>\n",
        "      <td> Cardigans &amp; Knitwear</td>\n",
        "      <td> Apparel and Accessories</td>\n",
        "      <td>...</td>\n",
        "      <td>  4895</td>\n",
        "      <td> 236</td>\n",
        "      <td> 0</td>\n",
        "      <td> 17</td>\n",
        "      <td> 197</td>\n",
        "      <td> 0</td>\n",
        "      <td> 21</td>\n",
        "      <td> 242</td>\n",
        "      <td> 1</td>\n",
        "      <td> 19</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 260398</td>\n",
        "      <td>   blue</td>\n",
        "      <td> Female</td>\n",
        "      <td> 2014-01-23 18:56:40</td>\n",
        "      <td> Autumn / Winter</td>\n",
        "      <td>           Extu</td>\n",
        "      <td> 151912</td>\n",
        "      <td>  75012</td>\n",
        "      <td>           Long Pants</td>\n",
        "      <td> Apparel and Accessories</td>\n",
        "      <td>...</td>\n",
        "      <td>  4952</td>\n",
        "      <td>  55</td>\n",
        "      <td> 3</td>\n",
        "      <td> 14</td>\n",
        "      <td> 239</td>\n",
        "      <td> 0</td>\n",
        "      <td> 17</td>\n",
        "      <td> 207</td>\n",
        "      <td> 2</td>\n",
        "      <td> 17</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 261307</td>\n",
        "      <td> purple</td>\n",
        "      <td> Female</td>\n",
        "      <td> 2014-03-04 17:28:17</td>\n",
        "      <td> Autumn / Winter</td>\n",
        "      <td>         Sanban</td>\n",
        "      <td> 186260</td>\n",
        "      <td>  89543</td>\n",
        "      <td>    Leggings &amp; Tights</td>\n",
        "      <td> Apparel and Accessories</td>\n",
        "      <td>...</td>\n",
        "      <td>  9297</td>\n",
        "      <td> 304</td>\n",
        "      <td> 1</td>\n",
        "      <td> 41</td>\n",
        "      <td> 135</td>\n",
        "      <td> 4</td>\n",
        "      <td> 14</td>\n",
        "      <td> 240</td>\n",
        "      <td> 1</td>\n",
        "      <td> 21</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 261505</td>\n",
        "      <td>   blue</td>\n",
        "      <td>   Male</td>\n",
        "      <td> 2014-02-03 14:43:08</td>\n",
        "      <td> Autumn / Winter</td>\n",
        "      <td>         LEVI'S</td>\n",
        "      <td> 504623</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>                Jeans</td>\n",
        "      <td> Apparel and Accessories</td>\n",
        "      <td>...</td>\n",
        "      <td> 12840</td>\n",
        "      <td> 143</td>\n",
        "      <td> 4</td>\n",
        "      <td> 18</td>\n",
        "      <td> 280</td>\n",
        "      <td> 2</td>\n",
        "      <td> 18</td>\n",
        "      <td>  82</td>\n",
        "      <td> 0</td>\n",
        "      <td> 25</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 263497</td>\n",
        "      <td> orange</td>\n",
        "      <td> Female</td>\n",
        "      <td> 2014-02-28 11:12:05</td>\n",
        "      <td> Autumn / Winter</td>\n",
        "      <td>        Anynome</td>\n",
        "      <td> 549214</td>\n",
        "      <td> 384303</td>\n",
        "      <td>                Batik</td>\n",
        "      <td> Apparel and Accessories</td>\n",
        "      <td>...</td>\n",
        "      <td>  4654</td>\n",
        "      <td> 181</td>\n",
        "      <td> 1</td>\n",
        "      <td> 21</td>\n",
        "      <td> 125</td>\n",
        "      <td> 4</td>\n",
        "      <td> 27</td>\n",
        "      <td>  52</td>\n",
        "      <td> 0</td>\n",
        "      <td> 21</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 264830</td>\n",
        "      <td>   gold</td>\n",
        "      <td> Female</td>\n",
        "      <td> 2014-02-10 11:40:20</td>\n",
        "      <td> Autumn / Winter</td>\n",
        "      <td>           evb*</td>\n",
        "      <td> 467094</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> Sandals &amp; Flip Flops</td>\n",
        "      <td>                   Shoes</td>\n",
        "      <td>...</td>\n",
        "      <td>  6366</td>\n",
        "      <td> 216</td>\n",
        "      <td> 3</td>\n",
        "      <td> 15</td>\n",
        "      <td>  60</td>\n",
        "      <td> 4</td>\n",
        "      <td>  6</td>\n",
        "      <td>  88</td>\n",
        "      <td> 2</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 265471</td>\n",
        "      <td>  beige</td>\n",
        "      <td> Female</td>\n",
        "      <td> 2014-02-19 16:35:08</td>\n",
        "      <td> Autumn / Winter</td>\n",
        "      <td>           Extu</td>\n",
        "      <td> 120180</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>     Blouses &amp; Tunics</td>\n",
        "      <td> Apparel and Accessories</td>\n",
        "      <td>...</td>\n",
        "      <td>   671</td>\n",
        "      <td>  74</td>\n",
        "      <td> 3</td>\n",
        "      <td>  6</td>\n",
        "      <td> 126</td>\n",
        "      <td> 4</td>\n",
        "      <td> 21</td>\n",
        "      <td> 273</td>\n",
        "      <td> 2</td>\n",
        "      <td> 16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> 265763</td>\n",
        "      <td>   grey</td>\n",
        "      <td>   Male</td>\n",
        "      <td> 2014-02-20 18:25:09</td>\n",
        "      <td> Spring / Summer</td>\n",
        "      <td>          Dan's</td>\n",
        "      <td>  78436</td>\n",
        "      <td>    NaN</td>\n",
        "      <td> Sandals &amp; Flip Flops</td>\n",
        "      <td>                   Shoes</td>\n",
        "      <td>...</td>\n",
        "      <td>  5386</td>\n",
        "      <td> 181</td>\n",
        "      <td> 5</td>\n",
        "      <td> 31</td>\n",
        "      <td> 166</td>\n",
        "      <td> 1</td>\n",
        "      <td> 10</td>\n",
        "      <td> 213</td>\n",
        "      <td> 0</td>\n",
        "      <td>  7</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>10 rows \u00d7 26 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "   product_id  colors  gender         activated_at     season_group  \\\n",
        "0      254010   green  Female  2014-04-11 17:44:47  Autumn / Winter   \n",
        "1      257247   brown  Female  2014-01-17 12:59:56  Autumn / Winter   \n",
        "2      259356   beige    Male  2014-01-21 16:34:25  Autumn / Winter   \n",
        "3      260398    blue  Female  2014-01-23 18:56:40  Autumn / Winter   \n",
        "4      261307  purple  Female  2014-03-04 17:28:17  Autumn / Winter   \n",
        "5      261505    blue    Male  2014-02-03 14:43:08  Autumn / Winter   \n",
        "6      263497  orange  Female  2014-02-28 11:12:05  Autumn / Winter   \n",
        "7      264830    gold  Female  2014-02-10 11:40:20  Autumn / Winter   \n",
        "8      265471   beige  Female  2014-02-19 16:35:08  Autumn / Winter   \n",
        "9      265763    grey    Male  2014-02-20 18:25:09  Spring / Summer   \n",
        "\n",
        "            brand  original_price  special_price          sub_cat_type  \\\n",
        "0          Wardah           22112            NaN    Cleansers & Toners   \n",
        "1        Sidewalk          308449         119607     Ballerina & Flats   \n",
        "2  Noir Sur Blanc          350911         279273  Cardigans & Knitwear   \n",
        "3            Extu          151912          75012            Long Pants   \n",
        "4          Sanban          186260          89543     Leggings & Tights   \n",
        "5          LEVI'S          504623            NaN                 Jeans   \n",
        "6         Anynome          549214         384303                 Batik   \n",
        "7            evb*          467094            NaN  Sandals & Flip Flops   \n",
        "8            Extu          120180            NaN      Blouses & Tunics   \n",
        "9           Dan's           78436            NaN  Sandals & Flip Flops   \n",
        "\n",
        "                  cat_type           ...             \\\n",
        "0                   Beauty           ...              \n",
        "1                    Shoes           ...              \n",
        "2  Apparel and Accessories           ...              \n",
        "3  Apparel and Accessories           ...              \n",
        "4  Apparel and Accessories           ...              \n",
        "5  Apparel and Accessories           ...              \n",
        "6  Apparel and Accessories           ...              \n",
        "7                    Shoes           ...              \n",
        "8  Apparel and Accessories           ...              \n",
        "9                    Shoes           ...              \n",
        "\n",
        "   impressions_count_last_30days  net_sale_count  net_sale_count_last_7days  \\\n",
        "0                           6810             196                          5   \n",
        "1                          17780             315                          1   \n",
        "2                           4895             236                          0   \n",
        "3                           4952              55                          3   \n",
        "4                           9297             304                          1   \n",
        "5                          12840             143                          4   \n",
        "6                           4654             181                          1   \n",
        "7                           6366             216                          3   \n",
        "8                            671              74                          3   \n",
        "9                           5386             181                          5   \n",
        "\n",
        "   net_sale_count_last_30days  rejected_returned_sale_count  \\\n",
        "0                          42                           133   \n",
        "1                           8                           172   \n",
        "2                          17                           197   \n",
        "3                          14                           239   \n",
        "4                          41                           135   \n",
        "5                          18                           280   \n",
        "6                          21                           125   \n",
        "7                          15                            60   \n",
        "8                           6                           126   \n",
        "9                          31                           166   \n",
        "\n",
        "   rejected_returned_sale_count_last_7days  \\\n",
        "0                                        1   \n",
        "1                                        4   \n",
        "2                                        0   \n",
        "3                                        0   \n",
        "4                                        4   \n",
        "5                                        2   \n",
        "6                                        4   \n",
        "7                                        4   \n",
        "8                                        4   \n",
        "9                                        1   \n",
        "\n",
        "   rejected_returned_sale_count_last_30days  canceled_sale_count  \\\n",
        "0                                        24                   85   \n",
        "1                                        18                   69   \n",
        "2                                        21                  242   \n",
        "3                                        17                  207   \n",
        "4                                        14                  240   \n",
        "5                                        18                   82   \n",
        "6                                        27                   52   \n",
        "7                                         6                   88   \n",
        "8                                        21                  273   \n",
        "9                                        10                  213   \n",
        "\n",
        "   canceled_sale_count_last_7days  canceled_sale_count_last_30days  \n",
        "0                               2                               27  \n",
        "1                               3                               19  \n",
        "2                               1                               19  \n",
        "3                               2                               17  \n",
        "4                               1                               21  \n",
        "5                               0                               25  \n",
        "6                               0                               21  \n",
        "7                               2                               10  \n",
        "8                               2                               16  \n",
        "9                               0                                7  \n",
        "\n",
        "[10 rows x 26 columns]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we take out columns that will not be fit into our model for training: \n",
      "\n",
      "product_id\n",
      "\n",
      "activated_at\n",
      "\n",
      "views_count\n",
      "\n",
      "impressions_count\n",
      "\n",
      "net_sale_count\n",
      "\n",
      "rejected_returned_sale_count\n",
      "\n",
      "canceled_sale_count"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "df = df.drop(['product_id', 'activated_at', 'views_count', 'impressions_count', 'net_sale_count', 'rejected_returned_sale_count', 'canceled_sale_count'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 4000 entries, 0 to 3999\n",
        "Data columns (total 19 columns):\n",
        "colors                                      4000 non-null object\n",
        "gender                                      4000 non-null object\n",
        "season_group                                4000 non-null object\n",
        "brand                                       4000 non-null object\n",
        "original_price                              4000 non-null float64\n",
        "special_price                               2337 non-null float64\n",
        "sub_cat_type                                4000 non-null object\n",
        "cat_type                                    4000 non-null object\n",
        "stock                                       4000 non-null int64\n",
        "views_count_last_7days                      4000 non-null int64\n",
        "views_count_last_30days                     4000 non-null int64\n",
        "impressions_count_last_7days                4000 non-null int64\n",
        "impressions_count_last_30days               4000 non-null int64\n",
        "net_sale_count_last_7days                   4000 non-null int64\n",
        "net_sale_count_last_30days                  4000 non-null int64\n",
        "rejected_returned_sale_count_last_7days     4000 non-null int64\n",
        "rejected_returned_sale_count_last_30days    4000 non-null int64\n",
        "canceled_sale_count_last_7days              4000 non-null int64\n",
        "canceled_sale_count_last_30days             4000 non-null int64\n",
        "dtypes: float64(2), int64(11), object(6)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we observe that some categorical columns, like \"colors\", may have too many disctinct values, which may cause a burden to create dummies variables later, as shown below. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "colorCount = Counter(df['colors'])\n",
      "for i in colorCount.most_common():\n",
      "    print i[0], i[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "black 924\n",
        "blue 656\n",
        "grey 341\n",
        "white 336\n",
        "red 280\n",
        "brown 259\n",
        "beige 244\n",
        "pink 175\n",
        "green 155\n",
        "purple 96\n",
        "orange 71\n",
        "yellow 64\n",
        "navy 45\n",
        "gold 39\n",
        "black,white,multi 32\n",
        "multi 28\n",
        "silver 20\n",
        "black,white 18\n",
        "black,multi,grey 18\n",
        "white,blue,multi 14\n",
        "n/a 10\n",
        "multi,beige,brown 10\n",
        "black,red,multi 8\n",
        "black,multi 5\n",
        "black,blue,multi 5\n",
        "orange,blue,multi 4\n",
        "multi,grey,brown 4\n",
        "black,multi,brown 4\n",
        "green,multi,grey 3\n",
        "green,multi 3\n",
        "black,purple,multi 3\n",
        "white,multi,beige 3\n",
        "black,red 3\n",
        "white,multi,brown 3\n",
        "black,pink,multi 3\n",
        "pink,blue,multi 3\n",
        "orange,multi,brown 3\n",
        "black,blue 3\n",
        "white,pink,multi 3\n",
        "blue,grey 3\n",
        "pink,multi,beige 3\n",
        "blue,multi,grey 3\n",
        "black,multi,beige 2\n",
        "white,multi,grey 2\n",
        "red,multi 2\n",
        "yellow,green,multi 2\n",
        "red,blue,multi 2\n",
        "pink,grey 2\n",
        "white,blue 2\n",
        "red,multi,navy 2\n",
        "green,multi,beige 2\n",
        "white,grey 2\n",
        "red,multi,beige 2\n",
        "blue,navy 2\n",
        "black,multi,gold 2\n",
        "pink,yellow,multi 2\n",
        "white,red,multi,navy 2\n",
        "green,multi,brown 2\n",
        "black,brown 2\n",
        "pink,multi 2\n",
        "white,red,blue,multi 2\n",
        "white,red 2\n",
        "white,orange,multi 2\n",
        "beige,navy 1\n",
        "multi,beige 1\n",
        "red,purple,multi 1\n",
        "pink,purple,multi 1\n",
        "black,white,multi,brown 1\n",
        "black,yellow,blue,multi 1\n",
        "black,orange,multi 1\n",
        "green,blue,multi 1\n",
        "black,white,green,blue,multi 1\n",
        "multi,gold,brown 1\n",
        "white,beige 1\n",
        "green,multi,beige,brown 1\n",
        "blue,purple 1\n",
        "multi,beige,grey 1\n",
        "black,green 1\n",
        "multi,gold,beige 1\n",
        "pink,multi,gold 1\n",
        "blue,multi 1\n",
        "red,blue,multi,grey 1\n",
        "black,white,red,multi 1\n",
        "blue,multi,beige 1\n",
        "orange,multi,navy 1\n",
        "pink,multi,grey 1\n",
        "yellow,multi,beige 1\n",
        "orange,multi,grey 1\n",
        "black,pink 1\n",
        "white,multi,navy 1\n",
        "black,grey 1\n",
        "yellow,blue,multi 1\n",
        "yellow,brown 1\n",
        "black,white,pink,multi 1\n",
        "blue,purple,multi 1\n",
        "black,yellow,multi 1\n",
        "multi,brown 1\n",
        "multi,grey 1\n",
        "red,orange,multi 1\n",
        "white,purple,multi 1\n",
        "orange,green,multi,brown 1\n",
        "pink,multi,navy 1\n",
        "red,brown 1\n",
        "red,multi,grey 1\n",
        "pink,purple 1\n",
        "multi,beige,navy 1\n",
        "white,red,multi 1\n",
        "black,multi,silver 1\n",
        "pink,purple,multi,brown 1\n",
        "multi,navy,brown 1\n",
        "multi,grey,navy 1\n",
        "black,blue,multi,beige 1\n",
        "black,multi,navy,brown 1\n",
        "blue,multi,brown 1\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We may need to find a way to reduce the total number of distinct values. \n",
      "As discovered from above, we can treat all colors categories from \"n/a\" downwards as \"Others\", and leave the ones above unchanged. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "remainedColors = [\n",
      "'black',\n",
      "'blue',\n",
      "'grey',\n",
      "'white',\n",
      "'red',\n",
      "'brown',\n",
      "'beige',\n",
      "'pink',\n",
      "'green',\n",
      "'purple',\n",
      "'orange',\n",
      "'yellow',\n",
      "'navy',\n",
      "'gold',\n",
      "'black,white,multi',\n",
      "'multi',\n",
      "'silver',\n",
      "'black,white',\n",
      "'black,multi,grey',\n",
      "'white,blue,multi'\n",
      "]\n",
      "df['colors_label'] = df['colors'].apply(lambda x: x if x in remainedColors else 'Others')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "colors_Label_Count = Counter(df['colors_label'])\n",
      "for i in colors_Label_Count.most_common():\n",
      "    print i[0], i[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "black 924\n",
        "blue 656\n",
        "grey 341\n",
        "white 336\n",
        "red 280\n",
        "brown 259\n",
        "beige 244\n",
        "Others 185\n",
        "pink 175\n",
        "green 155\n",
        "purple 96\n",
        "orange 71\n",
        "yellow 64\n",
        "navy 45\n",
        "gold 39\n",
        "black,white,multi 32\n",
        "multi 28\n",
        "silver 20\n",
        "black,white 18\n",
        "black,multi,grey 18\n",
        "white,blue,multi 14\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, because some column's values may be very special, like the \"brand\" column, we may not wish to do the same for them even if the column might also include many distinct values.\n",
      "\n",
      "Now let's create dummies variables for all categorical columns\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 4000 entries, 0 to 3999\n",
        "Data columns (total 20 columns):\n",
        "colors                                      4000 non-null object\n",
        "gender                                      4000 non-null object\n",
        "season_group                                4000 non-null object\n",
        "brand                                       4000 non-null object\n",
        "original_price                              4000 non-null float64\n",
        "special_price                               2337 non-null float64\n",
        "sub_cat_type                                4000 non-null object\n",
        "cat_type                                    4000 non-null object\n",
        "stock                                       4000 non-null int64\n",
        "views_count_last_7days                      4000 non-null int64\n",
        "views_count_last_30days                     4000 non-null int64\n",
        "impressions_count_last_7days                4000 non-null int64\n",
        "impressions_count_last_30days               4000 non-null int64\n",
        "net_sale_count_last_7days                   4000 non-null int64\n",
        "net_sale_count_last_30days                  4000 non-null int64\n",
        "rejected_returned_sale_count_last_7days     4000 non-null int64\n",
        "rejected_returned_sale_count_last_30days    4000 non-null int64\n",
        "canceled_sale_count_last_7days              4000 non-null int64\n",
        "canceled_sale_count_last_30days             4000 non-null int64\n",
        "colors_label                                4000 non-null object\n",
        "dtypes: float64(2), int64(11), object(7)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.concat([df, pd.get_dummies(df['gender'], prefix='sex')], axis=1)\n",
      "df = pd.concat([df, pd.get_dummies(df['colors_label'], prefix='color')], axis=1)\n",
      "df = pd.concat([df, pd.get_dummies(df['season_group'], prefix='season')], axis=1)\n",
      "df = pd.concat([df, pd.get_dummies(df['brand'], prefix='brand')], axis=1)\n",
      "df = pd.concat([df, pd.get_dummies(df['sub_cat_type'], prefix='sub')], axis=1)\n",
      "df = pd.concat([df, pd.get_dummies(df['cat_type'], prefix='cat')], axis=1)\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.drop(['colors', 'gender', 'colors_label', 'season_group', 'brand', 'sub_cat_type', 'cat_type'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have created dummies variables for all categorical columns, the next step we would take is to calculate \"views_count\", \"impressions_count\", \"net_sale\", \"rejected_returned_count\", \"canceled_sale_count\" for the first 3 weeks of the month. \n",
      "\n",
      "And we will also create our target column: y. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "df['views_past'] = df['views_count_last_30days'] - df['views_count_last_7days']\n",
      "df['impressions_past'] = df['impressions_count_last_30days'] - df['impressions_count_last_7days']\n",
      "df['sale_past'] = df['net_sale_count_last_30days'] - df['net_sale_count_last_7days']\n",
      "df['rejected_past'] = df['rejected_returned_sale_count_last_30days'] - df['rejected_returned_sale_count_last_7days']\n",
      "df['canceled_past'] = df['canceled_sale_count_last_30days'] - df['canceled_sale_count_last_7days']\n",
      "\n",
      "# the target variables - dependent variables: using the last 7 days' data\n",
      "y = df['net_sale_count_last_7days']\n",
      "\n",
      "df = df.drop(['views_count_last_7days', 'views_count_last_30days','impressions_count_last_7days', 'impressions_count_last_30days',\n",
      "              'rejected_returned_sale_count_last_7days', 'rejected_returned_sale_count_last_30days', \n",
      "              'net_sale_count_last_30days', 'net_sale_count_last_7days', \n",
      "              'canceled_sale_count_last_7days', 'canceled_sale_count_last_30days'], axis=1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One more thing to note, since there are NaN values for column \"special_price\", we will simply set those NaN values to be the price of its \"original_price\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['special_price'] = df[['special_price', 'original_price']].apply(lambda x: x['original_price'] \n",
      "                                                                    if pd.isnull(x['special_price']) \n",
      "                                                                    else x['special_price'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2. Model training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see what we have got so far. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 4000 entries, 0 to 3999\n",
        "Columns: 504 entries, original_price to canceled_past\n",
        "dtypes: float64(498), int64(6)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head(10) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>original_price</th>\n",
        "      <th>special_price</th>\n",
        "      <th>stock</th>\n",
        "      <th>sex_Female</th>\n",
        "      <th>sex_Male</th>\n",
        "      <th>sex_Unisex</th>\n",
        "      <th>color_Others</th>\n",
        "      <th>color_beige</th>\n",
        "      <th>color_black</th>\n",
        "      <th>color_black,multi,grey</th>\n",
        "      <th>...</th>\n",
        "      <th>cat_Accessories</th>\n",
        "      <th>cat_Apparel and Accessories</th>\n",
        "      <th>cat_Beauty</th>\n",
        "      <th>cat_Shoes</th>\n",
        "      <th>cat_Underwear and Swimwear</th>\n",
        "      <th>views_past</th>\n",
        "      <th>impressions_past</th>\n",
        "      <th>sale_past</th>\n",
        "      <th>rejected_past</th>\n",
        "      <th>canceled_past</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  22112</td>\n",
        "      <td>  22112</td>\n",
        "      <td> 32</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 182</td>\n",
        "      <td>  5739</td>\n",
        "      <td> 37</td>\n",
        "      <td> 23</td>\n",
        "      <td> 25</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 308449</td>\n",
        "      <td> 119607</td>\n",
        "      <td> 22</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 133</td>\n",
        "      <td> 14607</td>\n",
        "      <td>  7</td>\n",
        "      <td> 14</td>\n",
        "      <td> 16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 350911</td>\n",
        "      <td> 279273</td>\n",
        "      <td>  5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  44</td>\n",
        "      <td>  3869</td>\n",
        "      <td> 17</td>\n",
        "      <td> 21</td>\n",
        "      <td> 18</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 151912</td>\n",
        "      <td>  75012</td>\n",
        "      <td> 15</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 138</td>\n",
        "      <td>  2791</td>\n",
        "      <td> 11</td>\n",
        "      <td> 17</td>\n",
        "      <td> 15</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 186260</td>\n",
        "      <td>  89543</td>\n",
        "      <td> 15</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 210</td>\n",
        "      <td>  7900</td>\n",
        "      <td> 40</td>\n",
        "      <td> 10</td>\n",
        "      <td> 20</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 504623</td>\n",
        "      <td> 504623</td>\n",
        "      <td> 71</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 212</td>\n",
        "      <td> 10348</td>\n",
        "      <td> 14</td>\n",
        "      <td> 16</td>\n",
        "      <td> 25</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 549214</td>\n",
        "      <td> 384303</td>\n",
        "      <td>  6</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 221</td>\n",
        "      <td>  3986</td>\n",
        "      <td> 20</td>\n",
        "      <td> 23</td>\n",
        "      <td> 21</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 467094</td>\n",
        "      <td> 467094</td>\n",
        "      <td> 15</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>  94</td>\n",
        "      <td>  5927</td>\n",
        "      <td> 12</td>\n",
        "      <td>  2</td>\n",
        "      <td>  8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 120180</td>\n",
        "      <td> 120180</td>\n",
        "      <td> 10</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 194</td>\n",
        "      <td>    12</td>\n",
        "      <td>  3</td>\n",
        "      <td> 17</td>\n",
        "      <td> 14</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>  78436</td>\n",
        "      <td>  78436</td>\n",
        "      <td>  6</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 245</td>\n",
        "      <td>  4401</td>\n",
        "      <td> 26</td>\n",
        "      <td>  9</td>\n",
        "      <td>  7</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>10 rows \u00d7 504 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "   original_price  special_price  stock  sex_Female  sex_Male  sex_Unisex  \\\n",
        "0           22112          22112     32           1         0           0   \n",
        "1          308449         119607     22           1         0           0   \n",
        "2          350911         279273      5           0         1           0   \n",
        "3          151912          75012     15           1         0           0   \n",
        "4          186260          89543     15           1         0           0   \n",
        "5          504623         504623     71           0         1           0   \n",
        "6          549214         384303      6           1         0           0   \n",
        "7          467094         467094     15           1         0           0   \n",
        "8          120180         120180     10           1         0           0   \n",
        "9           78436          78436      6           0         1           0   \n",
        "\n",
        "   color_Others  color_beige  color_black  color_black,multi,grey  \\\n",
        "0             0            0            0                       0   \n",
        "1             0            0            0                       0   \n",
        "2             0            1            0                       0   \n",
        "3             0            0            0                       0   \n",
        "4             0            0            0                       0   \n",
        "5             0            0            0                       0   \n",
        "6             0            0            0                       0   \n",
        "7             0            0            0                       0   \n",
        "8             0            1            0                       0   \n",
        "9             0            0            0                       0   \n",
        "\n",
        "            ...            cat_Accessories  cat_Apparel and Accessories  \\\n",
        "0           ...                          0                            0   \n",
        "1           ...                          0                            0   \n",
        "2           ...                          0                            1   \n",
        "3           ...                          0                            1   \n",
        "4           ...                          0                            1   \n",
        "5           ...                          0                            1   \n",
        "6           ...                          0                            1   \n",
        "7           ...                          0                            0   \n",
        "8           ...                          0                            1   \n",
        "9           ...                          0                            0   \n",
        "\n",
        "   cat_Beauty  cat_Shoes  cat_Underwear and Swimwear  views_past  \\\n",
        "0           1          0                           0         182   \n",
        "1           0          1                           0         133   \n",
        "2           0          0                           0          44   \n",
        "3           0          0                           0         138   \n",
        "4           0          0                           0         210   \n",
        "5           0          0                           0         212   \n",
        "6           0          0                           0         221   \n",
        "7           0          1                           0          94   \n",
        "8           0          0                           0         194   \n",
        "9           0          1                           0         245   \n",
        "\n",
        "   impressions_past  sale_past  rejected_past  canceled_past  \n",
        "0              5739         37             23             25  \n",
        "1             14607          7             14             16  \n",
        "2              3869         17             21             18  \n",
        "3              2791         11             17             15  \n",
        "4              7900         40             10             20  \n",
        "5             10348         14             16             25  \n",
        "6              3986         20             23             21  \n",
        "7              5927         12              2              8  \n",
        "8                12          3             17             14  \n",
        "9              4401         26              9              7  \n",
        "\n",
        "[10 rows x 504 columns]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "df - the training set - has 4000 rows of 504 columns, all of which are numbers. We are now good to move to the training stage.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "import random as rd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data = df.values\n",
      "target_data = y.values\n",
      "\n",
      "model = RandomForestClassifier(n_estimators = 100)\n",
      "model = model.fit(train_data, target_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3. Testing and validation "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have our model trained with past month data, we can test/validate our model with several ways below: "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "   1) Using the first 23 days data of next month to predict top sellers for the last 7 days of next month. <br><br>\n",
      "   \n",
      "\n",
      "   2) Using more transactions data (or more products) of first 23 days of this month to test<br><br>\n",
      "\n",
      "   \n",
      "   3) Using validation/cross_validation to split our existing data into 80/20, and validate this model by using existing data set<br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All three ways discribed above are feasible ways to test, or we can combine 3) and 1) to further fine tune the parameters by using cross validation, and test it using real transaction data set in the coming month.  "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}